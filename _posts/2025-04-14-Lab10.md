---
title: "Lab 10: Localization (sim)"
date: 2025-04-14 10:15:00 -500
categories: [labs]
tags: []
math: true
---

## Compute Control

A pose is a numpy array with elements [x, y, yaw]. The `compute_control()` function takes the current pose and the previous pose to calculate an pre-travel rotation (delta_rot_1), travel distance (delta_trans), and post-travel rotation (delta_rot_2). The pre-travel rotation is how much the robot much rotate to face the direction of its current position. The travel distance is self-explanatory. The post-travel rotation is how much the robot much rotate to match the current position yaw. Normalization happens after calculating the angles.

$$\Delta\phi_1=\tan^{-1}(\frac{Y_1-Y_0}{X_1-X_0})$$

$$\Delta d = \sqrt{(X_1-X_0)^2 + (Y_1-Y_0)^2}$$

$$\Delta\phi_2= \theta_2 - \tan^{-1}(\frac{Y_1-Y_0}{X_1-X_0}) - \Delta\phi_1$$


```python
def compute_control(cur_pose, prev_pose):
    """ Given the current and previous odometry poses, this function extracts
    the control information based on the odometry motion model.

    Args:
        cur_pose  ([Pose]): Current Pose
        prev_pose ([Pose]): Previous Pose 

    Returns:
        [delta_rot_1]: Rotation 1  (degrees)
        [delta_trans]: Translation (meters)
        [delta_rot_2]: Rotation 2  (degrees)
    """

    dX = cur_pose[0] - prev_pose[0]
    dY = cur_pose[1] - prev_pose[1]

    # rotation to face the current position
    delta_rot_1 = math.atan2(dY, dX) - prev_pose[2]
    norm_delta_rot_1 = mapper.normalize_angle(delta_rot_1)
    
    # distance of travel
    delta_trans = math.sqrt(dX**2 + dY**2)

    # rotation to face the current position yaw
    delta_rot_2 = cur_pose[2] - math.atan2(dY, dX) - delta_rot_1
    norm_delta_rot_2 = mapper.normalize_angle(delta_rot_2)
    
    return norm_delta_rot_1, delta_trans, norm_delta_rot_2
```

## Odometry Motion Model

The `odom_motion_model()` function is used to calculate the probability that the robot is at the current position given the previous position and a control data tuple. It uses the `gaussian()` method in the `BaseLocalization` class to calculate the individual probabilities for the pre-travel rotation (delta_rot_1), travel distance (delta_trans), and post-travel rotation (delta_rot_2). Then, it combines the probabilities using multiplication and returns the result. Normalization happens after calculating the angles.

```python
def odom_motion_model(cur_pose, prev_pose, u):
    """ Odometry Motion Model

    Args:
        cur_pose  ([Pose]): Current Pose
        prev_pose ([Pose]): Previous Pose
        (rot1, trans, rot2) (float, float, float): A tuple with control data in the format 
                                                   format (rot1, trans, rot2) with units (degrees, meters, degrees)
    Returns:
        prob [float]: Probability p(x'|x, u)
    """

    # calculate control values
    norm_delta_rot_1, delta_trans, norm_delta_rot_2 = compute_control(cur_pose, prev_pose)

    norm_control_rot_1 = mapper.normalize_angle(u[0])
    norm_control_rot_2 = mapper.normalize_angle(u[2])
    
    # calculate probability that the robot is in a particular orientation
    prob_rot_1 = loc.gaussian(norm_delta_rot_1, norm_control_rot_1, loc.odom_rot_sigma)
    prob_trans = loc.gaussian(delta_trans, u[1], loc.odom_trans_sigma)
    prob_rot_2 = loc.gaussian(norm_delta_rot_2, norm_control_rot_2, loc.odom_rot_sigma)
    
    # combine probabilities
    prob = prob_rot_1 * prob_trans * prob_rot_2
    
    return prob
```

## Prediction Step

The prediction step will loop through all combinations of x, y, and a (angle). For each combination, it will calculate the belief at that position and orientation. 
There are 1944 possible states, so if I have to go through all previous and current states, it would take 1944 x 1944 = 3779136 iterations of computation, which is extremely in efficient. Here, I implemented an optimization as specified by the lab manual. If a state has a probability less than 0.0001, it doesn't contribute a lot to the belief, so it can be skipped. This means that the total belief will no longer sum to one, which is why we need the normalization steps in the previous two functions. For the states with a probability greater than 0.0001, I loop through all combinations of x, y, and a again. Now that I have values for `prev_pose` and `curr_pos`, I created an odometry model using `odom_motion_model()`, calculated belief using `loc.bel`, and used them to update probabilities in `loc.bel_bar`.

```python
def prediction_step(cur_odom, prev_odom):
    """ Prediction step of the Bayes Filter.
    Update the probabilities in loc.bel_bar based on loc.bel from the previous time step and the odometry motion model.

    Args:
        cur_odom  ([Pose]): Current Pose
        prev_odom ([Pose]): Previous Pose
    """

    # loop through all combinations of (x, y, a)
    for x in range(mapper.MAX_CELLS_X):
        for y in range(mapper.MAX_CELLS_Y):
            for a in range(mapper.MAX_CELLS_A):
                
                # if the belief is less than 1e-4, it is highly unlikely that the robot is in that cell
                if loc.bel[x, y, a] >= 0.0001:
                    
                    # loop through all combinations of (x, y, a)
                    for x2 in range(mapper.MAX_CELLS_X):
                        for y2 in range(mapper.MAX_CELLS_Y):
                            for a2 in range(mapper.MAX_CELLS_A):
                                
                                # compare all plausible prev_poses with all curr_poses
                                prev_pose = mapper.from_map(x, y, a)
                                curr_pose = mapper.from_map(x2, y2, a2)
                                # calculate probability
                                prob = odom_motion_model(curr_pose, prev_pose, u)
                                # calculate belief of prev_pose
                                bel = loc.bel[x, y, a]
                                # adjust current based on previous
                                loc.bel_bar[x2, y2, a2] += (prob * bel)
```

## Sensor Model

This function calculates the probability the actual measurement with respect to the expected measurement. 
Every scanning rotation, the robot captures a certain amount of sensor readings, represented by `mapper.OBS_PER_CELL` (observations per cell). I did not change the default value. The obs (observation) array parameter holds the actual measurements. `loc.obs_range_data` holds the expected measurements. I use `loc.gaussian()` function to calculate the probability.

```python
def sensor_model(obs):
    """ This is the equivalent of p(z|x).

    Args:
        obs ([ndarray]): A 1D array consisting of the true observations for a specific robot pose in the map 

    Returns:
        [ndarray]: Returns a 1D array of size 18 (=loc.OBS_PER_CELL) with the likelihoods of each individual sensor measurement
    """

    prob_array = np.zeros(mapper.OBS_PER_CELL)
    for i in range(mapper.OBS_PER_CELL):
        prob_array[i] = loc.gaussian(loc.obs_range_data[i][0], obs[i], loc.sensor_sigma)
        
    return prob_array
```

## Update Step

When the robot receives a new measurement, the `update_step()` function updates the beliefs.

```python
def update_step():
    """ Update step of the Bayes Filter.
    Update the probabilities in loc.bel based on loc.bel_bar and the sensor model.
    """

    # loop through cells
    for x in range(mapper.MAX_CELLS_X):
        for y in range(mapper.MAX_CELLS_Y):
            for a in range(mapper.MAX_CELLS_A):
                # create sensor model
                sensorModel = np.prod(sensor_model(mapper.get_views(x, y, a)))
                # update beliefs for each cell
                loc.bel[x][y][a] = sensorModel * loc.bel_bar[x][y][a]
    # normalization step
    loc.bel = np.true_divide(bel ,np.sum(bel))
```

**Include the most probable state after each iteration of the bayes filter along with its probability and compare it with the ground truth pose. Write down your inference of when it works and when it doesnâ€™t.**


## Results
Here is the video of the best localization results (along the entire trajectory):
{% include embed/youtube.html id='IpVvybE3DVE' %}

The green line is the robot's actual position. The blue line is the Bayes filter predicted position. The red line is th odometry data. I am satisfied that the Bayes filter follows the actual position of the robot pretty well. The estimate is particularly accurate when the robot moves without turning. When the robots turns, the Bayes filter deviates from the actual a bit.

![(0,0)](/assets/img/lab10/localization_plot.png){: width="500"}

## References
- [**Ming He Lab 10 Report:**](https://minghe98.github.io/MingFRobots.github.io/#lab10) figuring out where to do normalization and other key concepts
- [**Mikayla Lahr Lab 10 Report:**](https://mikaylalahr.github.io/FastRobotsLabReports/startbootstrap-resume-master/dist/index.html#Lab%2010) help with the `prediction_step()` function
- [**Nidhi Sonwalker Lab 10 Report:**](https://ns14.github.io/lab10) finding ways to decrease the runtime
- Thank you Professor Helbling for helping me figure out why my plotter was running so slowly